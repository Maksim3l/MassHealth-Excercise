{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ebd1e7",
   "metadata": {},
   "source": [
    "# Face Recognition Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52deb349",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ea27476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import re\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aa2a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model(inputs = [inputImg, veriImg], outputs = [1,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6633a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPI')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12e485f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = os.path.join('data', 'positive')\n",
    "NEG = os.path.join('data', 'negative')\n",
    "ANC = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df77a32",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6831fe7",
   "metadata": {},
   "source": [
    "### Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc303aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_images(source_dir):\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"Creating directory: {source_dir}\")\n",
    "        os.makedirs(source_dir)\n",
    "\n",
    "    subfolders = [f.path for f in os.scandir(source_dir) if f.is_dir()]\n",
    "    \n",
    "    if not subfolders:\n",
    "        print(f\"No subfolders found in {source_dir}\")\n",
    "        return\n",
    "\n",
    "    image_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.bmp')\n",
    "   \n",
    "    copied_count = 0\n",
    "\n",
    "    processed_folders = []\n",
    "   \n",
    "    for folder in subfolders:\n",
    "        print(f\"Processing folder: {folder}\")\n",
    "        folder_processed = False\n",
    "       \n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(image_extensions):\n",
    "                    source_path = os.path.join(root, file)\n",
    "                    base_name = os.path.splitext(file)[0]\n",
    "                    extension = os.path.splitext(file)[1]\n",
    "                    counter = 1\n",
    "                    dest_file = file\n",
    "                   \n",
    "                    while os.path.exists(os.path.join(source_dir, dest_file)):\n",
    "                        dest_file = f\"{base_name}_{counter}{extension}\"\n",
    "                        counter += 1\n",
    "                   \n",
    "                    dest_path = os.path.join(source_dir, dest_file)\n",
    "                   \n",
    "                    try:\n",
    "                        shutil.copy2(source_path, dest_path)\n",
    "                        copied_count += 1\n",
    "                        folder_processed = True\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error copying {file}: {str(e)}\")\n",
    "        \n",
    "        if folder_processed:\n",
    "            processed_folders.append(folder)\n",
    "    \n",
    "    print(f\"\\nTotal images copied: {copied_count}\")\n",
    "    \n",
    "    if processed_folders:\n",
    "        print(\"\\nDeleting processed folders:\")\n",
    "        for folder in processed_folders:\n",
    "            try:\n",
    "                shutil.rmtree(folder)\n",
    "                print(f\"Deleted: {folder}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {folder}: {str(e)}\")\n",
    "\n",
    "consolidate_images(NEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting function because I messed up the top one and did it twice once with folder deleting and once without lol\n",
    "def remove_duplicate_images(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Error: Directory '{directory}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    files = os.listdir(directory)\n",
    "    files_to_delete = []\n",
    "    pattern = re.compile(r'^(.+)_1(\\.[^.]+)$')\n",
    "    deleted_count = 0\n",
    "    \n",
    "    print(f\"Scanning directory: {directory}\")\n",
    "\n",
    "    for file in files:\n",
    "        match = pattern.match(file)\n",
    "        if match:\n",
    "            base_name = match.group(1)\n",
    "            extension = match.group(2)\n",
    "            original_file = f\"{base_name}{extension}\"\n",
    "            if original_file in files:\n",
    "                files_to_delete.append(file)\n",
    "\n",
    "    for file in files_to_delete:\n",
    "        try:\n",
    "            file_path = os.path.join(directory, file)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file}\")\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nTotal duplicate files deleted: {deleted_count}\")\n",
    "\n",
    "remove_duplicate_images(NEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    frame = frame[120:120+250, 200:200+250, :]\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('a'):\n",
    "        img_name = os.path.join(ANC, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(f\"Saved anchor image: {img_name}\")\n",
    "    elif key == ord('p'):\n",
    "        img_name = os.path.join(POS, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(f\"Saved positive image: {img_name}\")\n",
    "    elif key == ord('q'):\n",
    "        print(\"Quitting...\")\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1688e1",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3a05d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\*'\n",
      "C:\\Users\\lokna\\AppData\\Local\\Temp\\ipykernel_31980\\2097756147.py:1: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  anchor = tf.data.Dataset.list_files(ANC+'\\*.jpg').take(300)\n",
      "C:\\Users\\lokna\\AppData\\Local\\Temp\\ipykernel_31980\\2097756147.py:2: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  positive = tf.data.Dataset.list_files(POS+'\\*.jpg').take(300)\n",
      "C:\\Users\\lokna\\AppData\\Local\\Temp\\ipykernel_31980\\2097756147.py:3: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  negative = tf.data.Dataset.list_files(NEG+'\\*.jpg').take(300)\n"
     ]
    }
   ],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC+'\\*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(POS+'\\*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(NEG+'\\*.jpg').take(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9d3156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test = anchor.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "595c8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img_path):\n",
    "    byte_img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img,(100,100))\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e20f876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7adda82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_twin(in_img, valid_img, label):\n",
    "    return(preprocess(in_img), preprocess(valid_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "123f19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preproc_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "184efee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.take(round(len(data)*0.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a87ab303",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.skip(round(len(data)*0.7))\n",
    "test_data = test_data.take(round(len(data)*0.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c2145",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65e9f2",
   "metadata": {},
   "source": [
    "### Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeding_make():\n",
    "    in_ = Input(shape=(100,100,3), name=\"in img\")\n",
    "\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(in_)\n",
    "    p1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(p1)\n",
    "    p2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(p2)\n",
    "    p4 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(p3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096,activation='sigmoid')(f1)\n",
    "\n",
    "    return Model(input=[in_],output=[d1],name=['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d3294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba78180c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
