{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ebd1e7",
   "metadata": {},
   "source": [
    "# Face Recognition Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52deb349",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea27476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import re\n",
    "import uuid\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model(inputs = [inputImg, veriImg], outputs = [1,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPI')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e485f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = os.path.join('data', 'training')\n",
    "TEST = os.path.join('data', 'test')\n",
    "ARCH = os.path.join('data', 'archive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df77a32",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6831fe7",
   "metadata": {},
   "source": [
    "### Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53fe7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    for d in [TRAIN, TEST]:\n",
    "        Path(d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_folders = [\n",
    "        folder for folder in os.listdir(ARCH)\n",
    "        if os.path.isdir(os.path.join(ARCH, folder))\n",
    "    ]\n",
    "\n",
    "    random.shuffle(all_folders)\n",
    "    split_idx = int(len(all_folders) * 0.7)\n",
    "    train_folders = all_folders[:split_idx]\n",
    "    test_folders = all_folders[split_idx:]\n",
    "\n",
    "    for folder_name in train_folders:\n",
    "        src = os.path.join(ARCH, folder_name)\n",
    "        dest = os.path.join(TRAIN, folder_name)\n",
    "        shutil.copytree(src, dest)\n",
    "        print(f\"Copied to training: {folder_name}\")\n",
    "\n",
    "    for folder_name in test_folders:\n",
    "        src = os.path.join(ARCH, folder_name)\n",
    "        dest = os.path.join(TEST, folder_name)\n",
    "        shutil.copytree(src, dest)\n",
    "        print(f\"Copied to testing: {folder_name}\")\n",
    "\n",
    "    print(f\"\\n✅ Done. {len(train_folders)} folders in training, {len(test_folders)} in test.\")\n",
    "\n",
    "split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting function because I messed up the top one and did it twice once with folder deleting and once without lol\n",
    "def remove_duplicate_images(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Error: Directory '{directory}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    files = os.listdir(directory)\n",
    "    files_to_delete = []\n",
    "    pattern = re.compile(r'^(.+)_1(\\.[^.]+)$')\n",
    "    deleted_count = 0\n",
    "    \n",
    "    print(f\"Scanning directory: {directory}\")\n",
    "\n",
    "    for file in files:\n",
    "        match = pattern.match(file)\n",
    "        if match:\n",
    "            base_name = match.group(1)\n",
    "            extension = match.group(2)\n",
    "            original_file = f\"{base_name}{extension}\"\n",
    "            if original_file in files:\n",
    "                files_to_delete.append(file)\n",
    "\n",
    "    for file in files_to_delete:\n",
    "        try:\n",
    "            file_path = os.path.join(directory, file)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file}\")\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nTotal duplicate files deleted: {deleted_count}\")\n",
    "\n",
    "remove_duplicate_images(NEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    frame = frame[120:120+250, 200:200+250, :]\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('a'):\n",
    "        img_name = os.path.join(ANC, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(f\"Saved anchor image: {img_name}\")\n",
    "    elif key == ord('p'):\n",
    "        img_name = os.path.join(POS, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(f\"Saved positive image: {img_name}\")\n",
    "    elif key == ord('q'):\n",
    "        print(\"Quitting...\")\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ea202e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs_from_directory(directory):\n",
    "    person_dirs = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    \n",
    "    anchor_paths = []\n",
    "    positive_paths = []\n",
    "    negative_paths = []\n",
    "    \n",
    "    for person in person_dirs:\n",
    "        person_path = os.path.join(directory, person)\n",
    "        person_images = [os.path.join(person_path, f) for f in os.listdir(person_path) \n",
    "                         if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        if len(person_images) < 2:\n",
    "            continue\n",
    "        for i in range(len(person_images)):\n",
    "            for j in range(i+1, len(person_images)):\n",
    "                anchor_paths.append(person_images[i])\n",
    "                positive_paths.append(person_images[j])\n",
    "        \n",
    "        other_people = [p for p in person_dirs if p != person]\n",
    "        \n",
    "        for anchor_img in person_images[:10]: \n",
    "            for other_person in other_people:\n",
    "                other_person_path = os.path.join(directory, other_person)\n",
    "                other_person_images = [os.path.join(other_person_path, f) \n",
    "                                       for f in os.listdir(other_person_path) \n",
    "                                       if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "                if not other_person_images:\n",
    "                    continue\n",
    "\n",
    "                for _ in range(min(5, len(other_person_images))): \n",
    "                    negative_img = random.choice(other_person_images)\n",
    "                    anchor_paths.append(anchor_img)\n",
    "                    negative_paths.append(negative_img)\n",
    "\n",
    "    positive_labels = tf.ones(len(positive_paths))\n",
    "    negative_labels = tf.zeros(len(negative_paths))\n",
    "    \n",
    "    all_anchor_paths = anchor_paths + anchor_paths\n",
    "    all_comparison_paths = positive_paths + negative_paths\n",
    "    all_labels = tf.concat([positive_labels, negative_labels], axis=0)\n",
    "    \n",
    "    anchor_ds = tf.data.Dataset.from_tensor_slices(all_anchor_paths)\n",
    "    comparison_ds = tf.data.Dataset.from_tensor_slices(all_comparison_paths)\n",
    "    labels_ds = tf.data.Dataset.from_tensor_slices(all_labels)\n",
    "    \n",
    "    return anchor_ds, comparison_ds, labels_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1688e1",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "595c8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img_path):\n",
    "    byte_img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img,(100,100))\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7adda82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_twin(in_img, valid_img, label):\n",
    "    return(preprocess(in_img), preprocess(valid_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets():\n",
    "    anchor_ds, comparison_ds, labels_ds = create_pairs_from_directory(TRAIN)\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((anchor_ds, comparison_ds, labels_ds))\n",
    "    dataset = dataset.map(preproc_twin)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(buffer_size=1024)\n",
    "    \n",
    "    dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "    train_size = int(dataset_size * 0.8)\n",
    "    \n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "    \n",
    "    train_dataset = train_dataset.batch(16)\n",
    "    train_dataset = train_dataset.prefetch(8)\n",
    "    \n",
    "    val_dataset = val_dataset.batch(16)\n",
    "    val_dataset = val_dataset.prefetch(8)\n",
    "    \n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c2145",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65e9f2",
   "metadata": {},
   "source": [
    "### Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeding_make():\n",
    "    in_ = Input(shape=(100,100,3), name=\"in img\")\n",
    "\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(in_)\n",
    "    p1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(p1)\n",
    "    p2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(p2)\n",
    "    p3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(p3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096,activation='sigmoid')(f1)\n",
    "\n",
    "    return Model(inputs=in_, outputs=d1, name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embeding_make()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, in_embed, valid_embed):\n",
    "        return tf.math.abs(in_embed - valid_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e57168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(): #Simanese\n",
    "    input_img = Input(name='input_img', shape=(100,100,3))\n",
    "    validation_img = Input(name='validation_img', shape=(100,100,3))\n",
    "\n",
    "    model_layer = L1Dist()\n",
    "    model_layer.name = 'distance'\n",
    "    distances = model_layer(embedding(input_img), embedding(validation_img))\n",
    "\n",
    "    classifier = Dense(1,activation='sigmoid')(distances)\n",
    "\n",
    "    return Model(inputs=[input_img, validation_img], outputs=classifier, name='SimaneseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78180c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96043ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f69853",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoints, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fc42fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def t_step(batch, model, optimizer, loss_fn):\n",
    "    with tf.GradientTape() as tape:  \n",
    "        anchor_img, comparison_img, y_true = batch\n",
    "        y_pred = model([anchor_img, comparison_img], training=True)\n",
    "        loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4e7a307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, epochs):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, epochs))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))  \n",
    "        for idx, batch in enumerate(data): \n",
    "            t_step(batch)\n",
    "            progbar.update(idx+1)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9656e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model(model, epochs=50):\n",
    "    train_dataset, val_dataset = prepare_datasets()\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "    val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')\n",
    "\n",
    "    checkpoint_dir = './checkpoints'\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        \n",
    "        progress_bar = tf.keras.utils.Progbar(len(train_dataset))\n",
    "        for batch_idx, batch in enumerate(train_dataset):\n",
    "            loss = t_step(batch, model, optimizer, loss_fn)\n",
    "            \n",
    "            train_loss(loss)\n",
    "            train_accuracy(batch[2], model([batch[0], batch[1]], training=False))\n",
    "            progress_bar.update(batch_idx + 1)\n",
    "\n",
    "        val_accuracy.reset_states()\n",
    "        for batch in val_dataset:\n",
    "            val_preds = model([batch[0], batch[1]], training=False)\n",
    "            val_accuracy(batch[2], val_preds)\n",
    "\n",
    "        print(f\"Loss: {train_loss.result():.4f}, Accuracy: {train_accuracy.result():.4f}, Val Accuracy: {val_accuracy.result():.4f}\")\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ec2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_data, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29346b68",
   "metadata": {},
   "source": [
    "### Test / Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da9287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in, test_val, y_true = test_data.as_numpy_iterator().next()\n",
    "y_hat = siamese_model.predict([test_in, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f9199",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1 if prediction > 0.5 else 0 for prediction in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e706660",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Recall()\n",
    "m.update_state(y_true, y_hat)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Precision()\n",
    "m.update_state(y_true, y_hat)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62cbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_in[0])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_val[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.save('face_verification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('face_verification.h5', custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ce63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_two_images(img1_path, img2_path, model):\n",
    "    def preprocess_single_image(img_path):\n",
    "        byte_img = tf.io.read_file(img_path)\n",
    "        img = tf.io.decode_jpeg(byte_img)\n",
    "        img = tf.image.resize(img, (100, 100))\n",
    "        img = img / 255.0\n",
    "        return img\n",
    "\n",
    "    img1 = preprocess_single_image(img1_path)\n",
    "    img2 = preprocess_single_image(img2_path)\n",
    "\n",
    "    # Add batch dimension\n",
    "    img1 = tf.expand_dims(img1, axis=0)\n",
    "    img2 = tf.expand_dims(img2, axis=0)\n",
    "\n",
    "    # Predict similarity\n",
    "    result = model.predict([img1, img2])\n",
    "    print(f\"Similarity score: {result[0][0]:.4f}\")\n",
    "    \n",
    "    if result[0][0] > 0.5:\n",
    "        print(\"✅ Match: Likely the same person\")\n",
    "    else:\n",
    "        print(\"❌ No Match: Likely different people\")\n",
    "\n",
    "# Example usage:\n",
    "test_on_two_images('C:/Users/lokna/Projects/MyReactNativeApp/extensions/face_auth/data/positive/496e69d0-3499-11f0-a4ad-e8fb1c79b654.jpg', 'C:/Users/lokna/Projects/MyReactNativeApp/extensions/face_auth/data/positive/4a5df055-3499-11f0-ae89-e8fb1c79b654.jpg', model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
